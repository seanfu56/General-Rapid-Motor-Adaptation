Hyperparameters: 
Env: HalfCheetah-v4
Algorithm: sac
Epochs: 3000
Hidden_dim: 256
LR: 0.0003
Noise_std_min: 0.1
Noise_std_max: 0.5
Noise_warm_ep: 3000
Seed: 2024
Batch_size: 256
Layer: 3
=============================================SquashedGaussianMLPActor(
  (net): Sequential(
    (0): Linear(in_features=17, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
  )
  (mu_layer): Linear(in_features=256, out_features=6, bias=True)
  (log_std_layer): Linear(in_features=256, out_features=6, bias=True)
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SquashedGaussianMLPActor                 [1, 6]                    --
├─Sequential: 1-1                        [1, 256]                  --
│    └─Linear: 2-1                       [1, 256]                  4,608
│    └─ReLU: 2-2                         [1, 256]                  --
│    └─Linear: 2-3                       [1, 256]                  65,792
│    └─ReLU: 2-4                         [1, 256]                  --
│    └─Linear: 2-5                       [1, 256]                  65,792
│    └─ReLU: 2-6                         [1, 256]                  --
├─Linear: 1-2                            [1, 6]                    1,542
├─Linear: 1-3                            [1, 6]                    1,542
==========================================================================================
Total params: 139,276
Trainable params: 139,276
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.14
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.56
Estimated Total Size (MB): 0.56
=======================================================================================================================================MLPQFunction(
  (q): Sequential(
    (0): Linear(in_features=23, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=1, bias=True)
    (7): Identity()
  )
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MLPQFunction                             [1]                       --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Linear: 2-1                       [1, 256]                  6,144
│    └─ReLU: 2-2                         [1, 256]                  --
│    └─Linear: 2-3                       [1, 256]                  65,792
│    └─ReLU: 2-4                         [1, 256]                  --
│    └─Linear: 2-5                       [1, 256]                  65,792
│    └─ReLU: 2-6                         [1, 256]                  --
│    └─Linear: 2-7                       [1, 1]                    257
│    └─Identity: 2-8                     [1, 1]                    --
==========================================================================================
Total params: 137,985
Trainable params: 137,985
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.14
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.55
Estimated Total Size (MB): 0.56
==========================================================================================