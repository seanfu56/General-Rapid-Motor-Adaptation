Hyperparameters: 
Env: Ant-v4
Algorithm: sac
Epochs: 3000
Hidden_dim: 256
LR: 0.0003
Noise_std_min: 0.1
Noise_std_max: 0.5
Noise_warm_ep: 3000
Seed: 2024
Batch_size: 256
Layer: 3
=============================================SquashedGaussianMLPActor(
  (net): Sequential(
    (0): Linear(in_features=27, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
  )
  (mu_layer): Linear(in_features=256, out_features=8, bias=True)
  (log_std_layer): Linear(in_features=256, out_features=8, bias=True)
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
SquashedGaussianMLPActor                 [1, 8]                    --
├─Sequential: 1-1                        [1, 256]                  --
│    └─Linear: 2-1                       [1, 256]                  7,168
│    └─ReLU: 2-2                         [1, 256]                  --
│    └─Linear: 2-3                       [1, 256]                  65,792
│    └─ReLU: 2-4                         [1, 256]                  --
│    └─Linear: 2-5                       [1, 256]                  65,792
│    └─ReLU: 2-6                         [1, 256]                  --
├─Linear: 1-2                            [1, 8]                    2,056
├─Linear: 1-3                            [1, 8]                    2,056
==========================================================================================
Total params: 142,864
Trainable params: 142,864
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.14
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.57
Estimated Total Size (MB): 0.58
=======================================================================================================================================MLPQFunction(
  (q): Sequential(
    (0): Linear(in_features=35, out_features=256, bias=True)
    (1): ReLU()
    (2): Linear(in_features=256, out_features=256, bias=True)
    (3): ReLU()
    (4): Linear(in_features=256, out_features=256, bias=True)
    (5): ReLU()
    (6): Linear(in_features=256, out_features=1, bias=True)
    (7): Identity()
  )
)
==========================================================================================
Layer (type:depth-idx)                   Output Shape              Param #
==========================================================================================
MLPQFunction                             [1]                       --
├─Sequential: 1-1                        [1, 1]                    --
│    └─Linear: 2-1                       [1, 256]                  9,216
│    └─ReLU: 2-2                         [1, 256]                  --
│    └─Linear: 2-3                       [1, 256]                  65,792
│    └─ReLU: 2-4                         [1, 256]                  --
│    └─Linear: 2-5                       [1, 256]                  65,792
│    └─ReLU: 2-6                         [1, 256]                  --
│    └─Linear: 2-7                       [1, 1]                    257
│    └─Identity: 2-8                     [1, 1]                    --
==========================================================================================
Total params: 141,057
Trainable params: 141,057
Non-trainable params: 0
Total mult-adds (Units.MEGABYTES): 0.14
==========================================================================================
Input size (MB): 0.00
Forward/backward pass size (MB): 0.01
Params size (MB): 0.56
Estimated Total Size (MB): 0.57
==========================================================================================